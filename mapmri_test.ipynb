{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[93mStarting the MAPMRI pipeline...\u001b[0m\n",
      "Using the following constants:\n",
      "MAPMRI Parameters: {'radial_order': 4, 'laplacian_regularization': True, 'laplacian_weighting': 0.2, 'positivity_constraint': False, 'global_constraints': False, 'pos_grid': 15, 'pos_radius': 'adaptive', 'anisotropic_scaling': True, 'eigenvalue_threshold': 0.0001, 'bval_threshold': inf, 'dti_scale_estimation': True, 'static_diffusivity': 0.0007, 'cvxpy_solver': None}\n",
      "Small delta: 0.015\n",
      "Big delta: 0.0353\n",
      "Using subset data: True\n",
      "Number of CPUs: 12\n",
      "Processing type: MultiProc\n",
      "\n",
      "\u001b[92mCreating Source Nodes.\u001b[0m\n",
      "\u001b[92mCreating Processing Nodes.\u001b[0m\n",
      "\u001b[92mCreating Output Nodes.\u001b[0m\n",
      "\u001b[92mConnecting Nodes.\n",
      "\u001b[0m\n",
      "230818-14:54:01,366 nipype.workflow INFO:\n",
      "\t Generated workflow graph: /Users/tanijarv/Documents/GitHub/mribrew/wf/mapmri_wf/graph.png (graph2use=orig, simple_form=True).\n",
      "230818-14:54:01,390 nipype.workflow INFO:\n",
      "\t Workflow mapmri_wf settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "230818-14:54:01,399 nipype.workflow INFO:\n",
      "\t Running in parallel.\n",
      "230818-14:54:01,401 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 2 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 12/12.\n",
      "230818-14:54:02,544 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"mapmri_wf.datasource\" in \"/Users/tanijarv/Documents/GitHub/mribrew/wf/mapmri_wf/_subject_id_BOF112_BioFINDER2_1000__20211023_1/datasource\".\n",
      "230818-14:54:02,545 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"mapmri_wf.datasource\" in \"/Users/tanijarv/Documents/GitHub/mribrew/wf/mapmri_wf/_subject_id_BOF112_BioFINDER2_1002__20210509_1/datasource\".\n",
      "230818-14:54:02,547 nipype.workflow INFO:\n",
      "\t [Node] Executing \"datasource\" <nipype.interfaces.io.DataGrabber>\n",
      "230818-14:54:02,548 nipype.workflow INFO:\n",
      "\t [Node] Executing \"datasource\" <nipype.interfaces.io.DataGrabber>\n",
      "230818-14:54:02,581 nipype.workflow INFO:\n",
      "\t [Node] Finished \"datasource\", elapsed time 0.001133s.\n",
      "230818-14:54:02,581 nipype.workflow INFO:\n",
      "\t [Node] Finished \"datasource\", elapsed time 0.001097s.\n",
      "230818-14:54:03,405 nipype.workflow INFO:\n",
      "\t [Job 0] Completed (mapmri_wf.datasource).\n",
      "230818-14:54:03,407 nipype.workflow INFO:\n",
      "\t [Job 1] Completed (mapmri_wf.datasource).\n",
      "230818-14:54:03,409 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 2 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 12/12.\n",
      "230818-14:54:03,461 nipype.workflow INFO:\n",
      "\t [Job 2] Cached (mapmri_wf.read_data).\n",
      "230818-14:54:03,464 nipype.workflow INFO:\n",
      "\t [Job 3] Cached (mapmri_wf.read_data).\n",
      "230818-14:54:05,463 nipype.workflow INFO:\n",
      "\t [Job 4] Cached (mapmri_wf.data_correction).\n",
      "230818-14:54:05,481 nipype.workflow INFO:\n",
      "\t [Job 5] Cached (mapmri_wf.data_correction).\n",
      "230818-14:54:07,512 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"mapmri_wf.fit_mapmri\".\n",
      "230818-14:54:07,537 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"mapmri_wf.fit_mapmri\".\n",
      "230818-14:54:07,968 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"mapmri_wf.fit_mapmri\" in \"/Users/tanijarv/Documents/GitHub/mribrew/wf/mapmri_wf/_subject_id_BOF112_BioFINDER2_1000__20211023_1/fit_mapmri\".\n",
      "230818-14:54:07,969 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"mapmri_wf.fit_mapmri\".\n",
      "230818-14:54:07,986 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"mapmri_wf.fit_mapmri\" in \"/Users/tanijarv/Documents/GitHub/mribrew/wf/mapmri_wf/_subject_id_BOF112_BioFINDER2_1002__20210509_1/fit_mapmri\".\n",
      "230818-14:54:07,987 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"mapmri_wf.fit_mapmri\".\n",
      "230818-14:54:08,49 nipype.workflow INFO:\n",
      "\t [Node] Executing \"fit_mapmri\" <nipype.interfaces.utility.wrappers.Function>\n",
      "230818-14:54:08,65 nipype.workflow INFO:\n",
      "\t [Node] Executing \"fit_mapmri\" <nipype.interfaces.utility.wrappers.Function>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4400 [00:00<?, ?it/s]/opt/anaconda3/envs/mri/lib/python3.11/site-packages/dipy/reconst/mapmri.py:488: RuntimeWarning: invalid value encountered in divide\n",
      "  coef = coef / sum(coef * self.Bm)\n",
      "/opt/anaconda3/envs/mri/lib/python3.11/site-packages/dipy/reconst/mapmri.py:488: RuntimeWarning: invalid value encountered in divide\n",
      "  coef = coef / sum(coef * self.Bm)\n",
      "  5%|▌         | 225/4400 [00:00<00:13, 317.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230818-14:54:09,414 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 2 tasks, and 0 jobs ready. Free memory (GB): 14.00/14.40, Free processors: 10/12.\n",
      "                     Currently running:\n",
      "                       * mapmri_wf.fit_mapmri\n",
      "                       * mapmri_wf.fit_mapmri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4400/4400 [00:14<00:00, 312.70it/s]\n",
      "100%|██████████| 4400/4400 [00:14<00:00, 311.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230818-14:54:23,493 nipype.workflow INFO:\n",
      "\t [Node] Finished \"fit_mapmri\", elapsed time 15.442741s.\n",
      "230818-14:54:23,537 nipype.workflow INFO:\n",
      "\t [Node] Finished \"fit_mapmri\", elapsed time 15.471365s.\n",
      "230818-14:54:25,448 nipype.workflow INFO:\n",
      "\t [Job 6] Completed (mapmri_wf.fit_mapmri).\n",
      "230818-14:54:25,450 nipype.workflow INFO:\n",
      "\t [Job 7] Completed (mapmri_wf.fit_mapmri).\n",
      "230818-14:54:25,453 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 2 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 12/12.\n",
      "230818-14:54:25,525 nipype.workflow INFO:\n",
      "\t [Job 8] Cached (mapmri_wf.metrics_to_nii).\n",
      "230818-14:54:25,554 nipype.workflow INFO:\n",
      "\t [Job 9] Cached (mapmri_wf.metrics_to_nii).\n",
      "230818-14:54:27,491 nipype.workflow INFO:\n",
      "\t [Job 10] Cached (mapmri_wf.rtop_corrected_to_nii).\n",
      "230818-14:54:27,494 nipype.workflow INFO:\n",
      "\t [Job 11] Cached (mapmri_wf.rtop_corrected_to_nii).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nipype import Function, Workflow, config, logging\n",
    "import nipype.interfaces.utility as niu\n",
    "import nipype.pipeline.engine as pe\n",
    "from nipype.interfaces import io\n",
    "\n",
    "from mribrew.utils import colours\n",
    "from mribrew.data_io import read_dwi_data\n",
    "from mribrew.mapmri_funcs import correct_neg_data, fit_mapmri_model, metrics_to_nifti, correct_metric_nifti\n",
    "\n",
    "# ---------------------- Set up directory structures and constant variables ----------------------\n",
    "cwd = os.getcwd()\n",
    "data_dir = os.path.join(cwd, 'data')\n",
    "raw_dir = os.path.join(data_dir, 'raw')\n",
    "proc_dir = os.path.join(data_dir, 'proc')\n",
    "wf_dir = os.path.join(cwd, 'wf')\n",
    "res_dir = os.path.join(data_dir, 'res')\n",
    "log_dir = os.path.join(wf_dir, 'log')\n",
    "\n",
    "subject_list = next(os.walk(proc_dir))[1]  # processed subjects\n",
    "\n",
    "# Computational variables\n",
    "use_subset_data = True\n",
    "processing_type = 'MultiProc' # or 'Linear'\n",
    "n_cpus = 12\n",
    "\n",
    "# MAPMRI variables\n",
    "big_delta, small_delta = 0.0353, 0.0150\n",
    "mapmri_params = dict(radial_order=4,\n",
    "                     laplacian_regularization=True,\n",
    "                     laplacian_weighting=0.2,\n",
    "                     positivity_constraint=False,\n",
    "                     global_constraints=False,\n",
    "                     pos_grid=15,\n",
    "                     pos_radius='adaptive',\n",
    "                     anisotropic_scaling=True,\n",
    "                     eigenvalue_threshold=1e-04,\n",
    "                     bval_threshold=np.inf,\n",
    "                     dti_scale_estimation=True,\n",
    "                     static_diffusivity=0.7e-3,\n",
    "                     cvxpy_solver=None)\n",
    "\n",
    "# Set up logging\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "config.update_config({'logging': {'log_directory': log_dir,'log_to_file': True}})\n",
    "logging.update_logging(config)\n",
    "\n",
    "print(f\"\\n{colours.UBOLD}{colours.CYELLOW}Starting the MAPMRI pipeline...{colours.CEND}\")\n",
    "print(f\"Using the following constants:\\n\"\n",
    "      f\"MAPMRI Parameters: {mapmri_params}\\n\"\n",
    "      f\"Small delta: {small_delta}\\n\"\n",
    "      f\"Big delta: {big_delta}\\n\"\n",
    "      f\"Using subset data: {use_subset_data}\\n\"\n",
    "      f\"Number of CPUs: {n_cpus}\\n\"\n",
    "      f\"Processing type: {processing_type}\\n\")\n",
    "\n",
    "# ---------------------- INPUT SOURCE NODES ----------------------\n",
    "print(colours.CGREEN + \"Creating Source Nodes.\" + colours.CEND)\n",
    "\n",
    "# Set up input files\n",
    "info = dict(dwi_eddy_file=[['subject_id', 'dwi', 'eddy_corrected.nii.gz']],\n",
    "            bvec_file=[['subject_id', 'dwi', 'gradChecked.bvec']],\n",
    "            bval_file=[['subject_id', 'dwi', 'gradChecked.bval']],\n",
    "            dwi_mask_file=[['subject_id', 'dwi', 'brain_dwi_mask.nii.gz']])\n",
    "\n",
    "# Set up infosource node\n",
    "infosource = pe.Node(niu.IdentityInterface(fields=['subject_id']), name='infosource')\n",
    "infosource.iterables = [('subject_id', subject_list)]\n",
    "infosource.inputs.big_delta = big_delta\n",
    "infosource.inputs.small_delta = small_delta\n",
    "infosource.inputs.use_subset_data = use_subset_data\n",
    "\n",
    "# Set up datasource node\n",
    "datasource = pe.Node(io.DataGrabber(infields=['subject_id'], outfields=list(info.keys())),\n",
    "                                    name='datasource')\n",
    "datasource.inputs.base_directory = proc_dir\n",
    "datasource.inputs.template = \"%s/%s/%s\"\n",
    "datasource.inputs.template_args = info\n",
    "datasource.inputs.sort_filelist = True\n",
    "\n",
    "# ---------------------- PROCESSING NODES ----------------------\n",
    "print(colours.CGREEN + \"Creating Processing Nodes.\" + colours.CEND)\n",
    "\n",
    "# Set up a node for loading in DWI data (and apply mask) and gradient table\n",
    "read_data = pe.Node(Function(input_names=['data_file', 'mask_file',\n",
    "                                          'bvec_file', 'bval_file',\n",
    "                                          'big_delta', 'small_delta',\n",
    "                                          'use_subset_data'],\n",
    "                             output_names=['data', 'affine', 'gtab'],\n",
    "                             function=read_dwi_data),\n",
    "                    name='read_data')\n",
    "read_data.inputs.big_delta = big_delta\n",
    "read_data.inputs.small_delta = small_delta\n",
    "read_data.inputs.use_subset_data = use_subset_data\n",
    "\n",
    "# Set up a node for correcting negative values to average volume value per timepoint\n",
    "data_correction = pe.Node(Function(input_names=['data'],\n",
    "                                   output_names=['data_corrected'],\n",
    "                                   function=correct_neg_data),\n",
    "                          name='data_correction')\n",
    "\n",
    "# Set up a node for fitting data to the MAPMRI model\n",
    "fit_mapmri = pe.Node(Function(input_names=['data', 'gtab', 'mapmri_params'],\n",
    "                              output_names=['MSD', 'QIV', 'RTOP', 'RTAP', 'RTPP'],\n",
    "                              function=fit_mapmri_model),\n",
    "                     name='fit_mapmri')\n",
    "fit_mapmri.inputs.mapmri_params = mapmri_params\n",
    "\n",
    "# ---------------------- OUTPUT NODES ----------------------\n",
    "print(colours.CGREEN + \"Creating Output Nodes.\" + colours.CEND)\n",
    "\n",
    "# Set up a node for saving metrics as NIfTI\n",
    "metrics_to_nii = pe.Node(Function(input_names=['affine', 'MSD', 'QIV', 'RTOP', 'RTAP', \n",
    "                                               'RTPP', 'out_file_prefix', 'res_dir'],\n",
    "                              output_names=['MSD_file', 'QIV_file', 'RTOP_file', \n",
    "                                            'RTAP_file', 'RTPP_file'],\n",
    "                              function=metrics_to_nifti),\n",
    "                     name='metrics_to_nii')\n",
    "metrics_to_nii.inputs.res_dir = os.path.join(res_dir, 'mapmri')\n",
    "\n",
    "# Set up a node for correcting RTOP metric and saving as NIfTI \n",
    "rtop_corrected_to_nii = pe.Node(Function(input_names=['metric_path', 'threshold', \n",
    "                                                      'correct_neg', 'replace_with'],\n",
    "                              output_names=['out_file'],\n",
    "                              function=correct_metric_nifti),\n",
    "                     name='rtop_corrected_to_nii')\n",
    "rtop_corrected_to_nii.inputs.threshold = 2000000\n",
    "rtop_corrected_to_nii.inputs.correct_neg = True\n",
    "rtop_corrected_to_nii.inputs.replace_with = 0\n",
    "\n",
    "# ---------------------- CREATE WORKFLOW AND CONNECT NODES ----------------------\n",
    "print(colours.CGREEN + 'Connecting Nodes.\\n' + colours.CEND)\n",
    "\n",
    "workflow = Workflow(name='mapmri_wf', base_dir=f\"{wf_dir}\")\n",
    "workflow.connect([\n",
    "    (infosource, datasource, [('subject_id', 'subject_id')]),\n",
    "    (datasource, read_data, [('dwi_eddy_file', 'data_file'),\n",
    "                             ('dwi_mask_file', 'mask_file'),\n",
    "                             ('bvec_file', 'bvec_file'),\n",
    "                             ('bval_file', 'bval_file')]),\n",
    "    (read_data, data_correction, [('data', 'data')]),\n",
    "    (data_correction, fit_mapmri, [('data_corrected', 'data')]),\n",
    "    (read_data, fit_mapmri, [('gtab', 'gtab')]),\n",
    "    (fit_mapmri, metrics_to_nii, [('MSD', 'MSD'),\n",
    "                               ('QIV', 'QIV'),\n",
    "                               ('RTOP', 'RTOP'),\n",
    "                               ('RTAP', 'RTAP'),\n",
    "                               ('RTPP', 'RTPP')]),\n",
    "    (read_data, metrics_to_nii, [('affine', 'affine')]),\n",
    "    (infosource, metrics_to_nii, [('subject_id', 'out_file_prefix')]),\n",
    "    (metrics_to_nii, rtop_corrected_to_nii, [('RTOP_file', 'metric_path')])\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    workflow.write_graph(graph2use='orig')\n",
    "    workflow.run(plugin=processing_type, plugin_args={'n_procs' : n_cpus})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
